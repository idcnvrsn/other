scikit learn randomforestで学習した結果について　predict()した場合とpredict_probaした場合でmean absolute errorでスコア出したとき結果が異なる模様。
predict_probaは結果が揺らぐせいか？？

"Rでディープラーニング
R-3.2.1-win.exe
と
jdk-8u51-windows-x64.exe
でパッケージをzipで入れまくったらできた"
library(h2o)
localH2O = h2o.init(ip = ""localhost"", port = 54321, startH2O = TRUE)
# データの読み込み（今回はiris）

irisPath = system.file(""extdata"", ""iris.csv"", package = ""h2o"")

iris.hex = h2o.importFile(localH2O, path = irisPath)

h2o.deeplearning(x = 1:4, y = 5, training_frame = iris.hex, activation = ""Tanh"")

# H2Oのシャットダウン
h2o.shutdown(localH2O)"

"sql server データベースを違うディレクトリに移動したいとき、そのディレクトリにMSSQL$TESTDBを設定し、ユーザー権限(フル権限）を与える。
オブジェクト名：NT Service\MSSQL$TESTDB　場所：そのPC名
で設定できる。
アタッチ、デタッチでディレクトリ移動できるようになる。"	

データベース高速化	http://www.geocities.jp/mickindex/database/db_optimize.html

"chainerインストールしてもcupyのimport等に失敗していたがいちどuninstallし、
pip install --no-cache-dir chainer
でいけた。依存するライブラリを更新したせいかも。"	
pip install PySide==1.2.2　などとしてバージョンを指定してインストールできる	
Chainerはインストールの順番が大事か？VC++,nvidia ドライバー、chainerの順？	

python joblib.dump データサイズによっては？？Compress=1だと失敗する場合がある模様。無圧縮でシリアライズすればよい。	

"python anacondaにてpip install sklearn-deapしてもscipyの依存関係解決できず失敗。コンパイラが入っていないことが問題ではなかった。
Conda update scipy　すると　import scipyできなくなる（一緒にupdateされるnumpy等もimportできなくなる）。
Conda update conda,conda update anacondaしてから(加えてconda update scipyしてから？)、
pip install deap
pip install sklearn-deap
をインストールしたところうまくいった。"	

pythonのmultiprocessing　でなぜかipythonにソースコードを張り付けでは実行できず。	

pythonのmultiprocessing　でなぜかspyderのipythonだと何かで不具合が起こると再起動まで？うまく動かず。コンソールからpyhon ***.pyするのがベストか？Ipythonとは相性悪いのか？？	

xgboost gitからtortoisesvnを使ってデータを落とした。Full recursiveで全部落ちてくるので slnをもつ最新のバージョンにてjavawrapper以外を64bitReleaseでビルド。Python bindingフォルダでpython setup.py install
ビルドの段階でsetup.py内にビルド結果の絶対パスが記載されるので、他のPC等にコピーする際には注意。	

xgboost はmultioutputには対応していない模様。	

■chainerサンプル
https://github.com/pfnet/chainer/tree/master/examples
からサンプルをダウンロード
・mnist
python mnist.py --gpu 0

・imagenet
git clone https://github.com/BVLC/caffe.git

python assemble_data.py --workers=-1 --images=80000 --seed 831486

python crop.py caffe/data/flickr_style/images_raw caffe/data/flickr_style/images

python compute_mean.py data\flickr_style\train.txt

以下のようなコマンドライン発行
python train_imagenet.py -g 0 train.txt test.txt 2>&1 | tee log
python train_imagenet.py -g 0  data/flickr_style/train.txt  data/flickr_style/test.txt
python train_imagenet.py -g 0  data/flickr_style/train.txt  data/flickr_style/test.txt 2>&1 | tee log
